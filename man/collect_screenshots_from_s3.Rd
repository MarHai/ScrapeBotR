% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/collect_screenshots_from_s3.R
\name{collect_screenshots_from_s3}
\alias{collect_screenshots_from_s3}
\title{Bulk-download (and compress) screenshots stored on S3}
\usage{
collect_screenshots_from_s3(
  connection,
  aws_access,
  aws_secret,
  aws_bucket,
  run_uid = NULL,
  instance_uid = NULL,
  recipe_uid = NULL,
  include_inactive = FALSE,
  resize = FALSE,
  resize_max_width = NULL,
  resize_max_height = NULL,
  output_directory = "",
  verbose = TRUE
)
}
\arguments{
\item{connection}{A connection object, as retrieved from \code{\link[=connect]{connect()}}.}

\item{aws_access}{Character string. The AWS access key, as provided in the ScrapeBot config file under "awsaccess".}

\item{aws_secret}{Character string. The AWS secret, as provided in the ScrapeBot config file under "awssecret".}

\item{aws_bucket}{Character string. The AWS bucket, as provided in the ScrapeBot config file under "awsbucket".}

\item{run_uid}{Optional numeric UID or a vector of numeric UIDs of a specific run to collect data from. If \code{NULL}, either \code{instance_uid} or \code{recipe_uid} (or both) has to be provided. Defaults to \code{NULL}.}

\item{instance_uid}{Optional numeric UID or a vector of numeric UIDs of the instance to filter data for. If \code{NULL}, either \code{run_uid} or \code{recipe_uid} (or both) has to be provided. Defaults to \code{NULL}.}

\item{recipe_uid}{Optional numeric UID or a vector of numeric UIDs of the recipe to filter data for. If \code{NULL}, either \code{instance_uid} or \code{run_uid} (or both) has to be provided. Defaults to \code{NULL}.}

\item{include_inactive}{If \code{TRUE}, inactive recipes are included along active recipes; defaults to \code{FALSE}.}

\item{resize}{If \code{TRUE}, downloaded screenshots will be resized keeping their aspect ratio to the maximum width/height as provided. Use for file-size compression.}

\item{resize_max_width}{Integer indicating the maximum width images should be resized to (if \code{resize} is \code{TRUE}). Aspect ratio with \code{resize_max_height} will be respected.}

\item{resize_max_height}{Integer indicating the maximum height images should be resized to (if \code{resize} is \code{TRUE}). Aspect ratio with \code{resize_max_width} will be respected.}

\item{output_directory}{Character string holding the (relative) path to the directory into which the screenshot files should be downloaded.}

\item{verbose}{If \code{TRUE}, the function will show download progress bar to indicate how far it has come.}
}
\value{
A \link[tibble:tibble-package]{tibble} listing all matching run-data entries according to which screenshots should be found on S3. As such, it contains the same amount of rows as received from \code{get_run_data} when filtering for the respective parameters and S3 links for "screenshot"-containing recipe steps (i.e., \code{get_recipes} first, then \code{get_recipe_steps} and filter for "screenshot," then \code{get_run_data} and filter for S3 links). For each row, then, the local filename, width, height, and filesize (in bytes) as well as their respective counterparts on S3 (note that, without resizing, width/height/filesize should be practically the same).
}
\description{
Download screenshots previously stored on S3 through ScrapeBot instances. The function will collect those cases in the data that refer to S3-stored screenshots and download them to a local output directory. While doing so, the funtion can also resize images to save local disk space.
}
\examples{
\dontrun{

connection <- connect('my_db on localhost')
collect_screenshots_from_s3(
  connection,
  'my4cc3ssKey', 's3cr3t', 'scrapebotbucket',
  run_uid = 42
)
collect_screenshots_from_s3(
  connection,
  'my4cc3ssKey', 's3cr3t', 'scrapebotbucket',
  run_uid = 42,
  resize = TRUE, resize_max_width = 800
)
collect_screenshots_from_s3(
  connection,
  'my4cc3ssKey', 's3cr3t', 'scrapebotbucket',
  run_uid = 42,
  output_directory = 'download_dir/'
)
disconnect(connection)
}

}
